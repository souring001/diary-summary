{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import wordcloud, codecs\n",
    "import MeCab\n",
    "from janome.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = codecs.open('diary-202004.txt','r', 'utf-8', 'ignore')\n",
    "txt = file.read()\n",
    "\n",
    "m = MeCab.Tagger('')\n",
    "txt = text.replace('\\r','')\n",
    "parsed = m.parse(text)\n",
    "\n",
    "#助詞、助動詞を除いて単語結合\n",
    "splitted = ' '.join([x.split('\\t')[0] for x in parsed.splitlines()[:-1] if x.split('\\t')[1].split(',')[0] not in ['助詞', '助動詞']])\n",
    "\n",
    "# wordc = wordcloud.WordCloud(\n",
    "#         font_path='RiiTN_R.otf',\n",
    "#         background_color='white',\n",
    "#         contour_color='steelblue',\n",
    "#         width=800,\n",
    "#         height=600,\n",
    "#         contour_width=2).generate(splitted)\n",
    "# wordc.to_file('summary-202004.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zoom(25) の(15) さん(13) これ(12) ん(11) 人(10) こと(10) 2(9) 動画(9) 朝(9) 1(8) 俺(8) ((8) )(8) 時間(7) .(7) 時(6) ペ(6) 今日(6) 輝(5) 道(5) w(5) そう(5) 3(5) 公開(5) 電話(5) お(5) 今(5) :(5) 何(5) Rt(5) 戸塚(5) 生活(4) 0(4) もの(4) くん(4) 日(4) 話(4) さ(4) -(4) ところ(4) ZOZO(4) うどん(4) 活(4) 論文(4) 完成(4) データ(4) 研究(3) 翔太(3) 明日(3) "
     ]
    }
   ],
   "source": [
    "# 形態素解析オブジェクトの生成\n",
    "t = Tokenizer()\n",
    "\n",
    "# テキストを一行ずつ処理 --- (※4)\n",
    "word_dic = {}\n",
    "lines = txt.split(\"\\r\\n\")\n",
    "for line in lines:\n",
    "    malist = t.tokenize(line)\n",
    "    for w in malist:\n",
    "        word = w.surface\n",
    "        ps = w.part_of_speech # 品詞\n",
    "        if ps.find('名詞') < 0: continue # 名詞だけカウント --- (※5)\n",
    "        if not word in word_dic:\n",
    "            word_dic[word] = 0\n",
    "        word_dic[word] += 1 # カウント\n",
    "\n",
    "# よく使われる単語を表示 --- (※6)\n",
    "keys = sorted(word_dic.items(), key=lambda x:x[1], reverse=True)\n",
    "for word,cnt in keys[:50]:\n",
    "    print(\"{0}({1}) \".format(word,cnt), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "import zipfile\n",
    "import os.path, urllib.request as req\n",
    "\n",
    "# 銀河鉄道の夜のZIPファイルをダウンロード --- (※1)\n",
    "url = \"http://www.aozora.gr.jp/cards/000081/files/456_ruby_145.zip\"\n",
    "local = \"456_ruby_145.zip\"\n",
    "if not os.path.exists(local):\n",
    "    print(\"ZIPファイルをダウンロード\")\n",
    "    req.urlretrieve(url, local)\n",
    "\n",
    "# ZIPファイル内のテキストファイルを読む --- (※2)\n",
    "zf = zipfile.ZipFile(local, 'r') # zipファイルを読む\n",
    "fp= zf.open('gingatetsudono_yoru.txt', 'r') # アーカイブ内のテキストを読む\n",
    "bindata = fp.read()\n",
    "txt = bindata.decode('shift_jis') # テキストがShift_JISなのでデコード\n",
    "\n",
    "# 形態素解析オブジェクトの生成 --- (※3)\n",
    "t = Tokenizer()\n",
    "\n",
    "# テキストを一行ずつ処理 --- (※4)\n",
    "word_dic = {}\n",
    "lines = txt.split(\"\\r\\n\")\n",
    "for line in lines:\n",
    "    malist = t.tokenize(line)\n",
    "    for w in malist:\n",
    "        word = w.surface\n",
    "        ps = w.part_of_speech # 品詞\n",
    "        if ps.find('名詞') < 0: continue # 名詞だけカウント --- (※5)\n",
    "        if not word in word_dic:\n",
    "            word_dic[word] = 0\n",
    "        word_dic[word] += 1 # カウント\n",
    "\n",
    "# よく使われる単語を表示 --- (※6)\n",
    "keys = sorted(word_dic.items(), key=lambda x:x[1], reverse=True)\n",
    "for word,cnt in keys[:50]:\n",
    "    print(\"{0}({1}) \".format(word,cnt), end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
